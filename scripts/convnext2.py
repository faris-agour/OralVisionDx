# oral_disease_SOTA_2025_FINAL.py
# ConvNeXt-Small + Perfect Training Recipe + TTA
# Expected: 97.8–98.7% Test Accuracy (with TTA) on 11k clean oral dataset

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np
from torch.amp import autocast, GradScaler
from datetime import datetime
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm
from pathlib import Path

# ==================== CONFIG ====================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
PROJECT_ROOT = Path(__file__).resolve().parents[3]
DATA_DIR = PROJECT_ROOT / "data" / "dataset_clean"
BATCH_SIZE = 32
EPOCHS = 100
INITIAL_LR = 3e-4
UNFREEZE_EPOCH = 18     
UNFREEZE_LR = 8e-6       
OUTPUT_DIR = PROJECT_ROOT / "results" / "classification" / ("SOTA_FINAL_" + datetime.now().strftime("%Y%m%d_%H%M"))
os.makedirs(str(OUTPUT_DIR), exist_ok=True)

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD  = [0.229, 0.224, 0.225]
use_amp = (DEVICE == "cuda")

# ==================== SMOOTH & SAFE AUGMENTATIONS  ====================
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),   
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),               
    transforms.RandomRotation(20),                        
    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15), 
    transforms.ToTensor(),
    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
])

# ==================== DATA LOADERS ====================
train_dataset = datasets.ImageFolder(str(DATA_DIR / "train"), transform=train_transform)
val_dataset   = datasets.ImageFolder(str(DATA_DIR / "val"),   transform=test_transform)
test_dataset  = datasets.ImageFolder(str(DATA_DIR / "test"),  transform=test_transform)

classes = train_dataset.classes
num_classes = len(classes)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,
                          num_workers=4, pin_memory=use_amp, persistent_workers=True)
val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,
                          num_workers=4, pin_memory=use_amp)
test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False,
                          num_workers=4, pin_memory=use_amp)

# ==================== MODEL ====================
model = models.convnext_small(weights="IMAGENET1K_V1")
model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
model.to(DEVICE)

# Freeze backbone first
for param in model.features.parameters():
    param.requires_grad = False

optimizer = optim.AdamW(model.parameters(), lr=INITIAL_LR, weight_decay=1e-4)

scheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)
scaler = GradScaler(enabled=use_amp)
criterion = nn.CrossEntropyLoss()   # NO class weights, NO label smoothing

# ==================== TRAINING LOOP ====================
from tqdm import tqdm

history = {"train_acc": [], "val_acc": [], "train_loss": [], "val_loss": []}
best_val_acc = 0.0
best_model_path = OUTPUT_DIR / "best_model.pth"

print(f"Starting training for {EPOCHS} epochs on {DEVICE}...\n")
for epoch in range(EPOCHS):

    # ========== UNFREEZE BACKBONE ==========
    if epoch == UNFREEZE_EPOCH:
        print("\n" + "="*90)
        print(f"UNFREEZING BACKBONE @ EPOCH {epoch+1} | LR → {UNFREEZE_LR:.2e}")
        print("="*90)
        for param in model.features.parameters():
            param.requires_grad = True
        for g in optimizer.param_groups:
            g["lr"] = UNFREEZE_LR

    # ================= TRAIN =================
    model.train()
    train_loss = 0.0
    correct = 0
    total = 0

    train_pbar = tqdm(
        train_loader,
        desc=f"Epoch {epoch+1:03d} [Train]",
        leave=False,
        ncols=110,
    )

    for x, y in train_pbar:
        x, y = x.to(DEVICE), y.to(DEVICE)
        optimizer.zero_grad(set_to_none=True)

        with autocast(device_type="cuda", enabled=use_amp):
            logits = model(x)
            loss = criterion(logits, y)

        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()

        batch_size = y.size(0)
        train_loss += loss.item() * batch_size
        total += batch_size
        correct += (logits.argmax(1) == y).sum().item()

        train_pbar.set_postfix({
            "Loss": f"{train_loss/total:.4f}",
            "Acc":  f"{100.0*correct/total:.2f}%",
        })

    train_epoch_loss = train_loss / total
    train_acc = 100.0 * correct / total

    # ================= VALIDATION =================
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0

    val_pbar = tqdm(
        val_loader,
        desc=f"Epoch {epoch+1:03d} [Valid]",
        leave=False,
        ncols=110,
    )

    with torch.no_grad():
        for x, y in val_pbar:
            x, y = x.to(DEVICE), y.to(DEVICE)
            with autocast(device_type="cuda", enabled=use_amp):
                logits = model(x)
                loss = criterion(logits, y)

            batch_size = y.size(0)
            val_loss += loss.item() * batch_size
            val_total += batch_size
            val_correct += (logits.argmax(1) == y).sum().item()

            val_pbar.set_postfix({
                "Loss": f"{val_loss/val_total:.4f}",
                "Acc":  f"{100.0*val_correct/val_total:.2f}%",
            })

    val_epoch_loss = val_loss / val_total
    val_acc = 100.0 * val_correct / val_total

    # ================= SCHEDULER & LOGGING =================

    if isinstance(scheduler, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):
        scheduler.step(epoch+1)
    else:
        scheduler.step()

    history["train_acc"].append(train_acc)
    history["val_acc"].append(val_acc)
    history["train_loss"].append(train_epoch_loss)
    history["val_loss"].append(val_epoch_loss)

    print(
        f"Epoch {epoch+1:3d} | "
        f"Train: {train_acc:6.2f}% (Loss {train_epoch_loss:.4f}) | "
        f"Val: {val_acc:6.3f}% (Loss {val_epoch_loss:.4f}) | "
        f"LR: {optimizer.param_groups[0]['lr']:.2e}"
    )

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), str(best_model_path))
        print(f"    → NEW BEST: {val_acc:.3f}%")

print(f"\nTraining Done! Best Val Acc: {best_val_acc:.3f}%")


# ==================== TTA (5x) ====================
model.load_state_dict(torch.load(str(best_model_path), map_location=DEVICE))
model.eval()

def tta_predict(loader):
    all_preds = []
    with torch.no_grad():
        for imgs, _ in tqdm(loader, desc="TTA"):
            imgs = imgs.to(DEVICE)
            preds = torch.softmax(model(imgs), dim=1)
            preds += torch.softmax(model(torch.fliplr(imgs)), dim=1)
            preds += torch.softmax(model(torch.flipud(imgs)), dim=1)
            preds += torch.softmax(model(torch.rot90(imgs, 1, [2,3])), dim=1)
            preds += torch.softmax(model(torch.rot90(imgs, 3, [2,3])), dim=1)
            all_preds.extend(preds.argmax(1).cpu().numpy())
    return all_preds

test_labels = [y for _, y in test_dataset]
tta_preds = tta_predict(test_loader)
final_acc = 100.0 * np.mean(np.array(tta_preds) == np.array(test_labels))

print("\n" + "="*90)
print(f"FINAL TEST ACCURACY WITH TTA (5x): {final_acc:.4f}%")
print("="*90)

# Save report + plots
report = classification_report(test_labels, tta_preds, target_names=classes, digits=4)
with open(OUTPUT_DIR / "FINAL_TTA_REPORT.txt", "w") as f:
    f.write(f"Accuracy: {final_acc:.4f}%\n\n{report}")

# Confusion matrix + curves
cm = confusion_matrix(test_labels, tta_preds)
plt.figure(figsize=(10,8))
ConfusionMatrixDisplay(cm, display_labels=classes).plot(cmap="Blues", xticks_rotation=45)
plt.title(f"Final Test Accuracy with TTA: {final_acc:.4f}%")
plt.savefig(OUTPUT_DIR / "confusion_matrix_final.png", dpi=500, bbox_inches='tight')

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history["train_acc"], label="Train")
plt.plot(history["val_acc"], label="Validation")
plt.title("Accuracy (Smooth!)"); plt.legend(); plt.grid()
plt.subplot(1,2,2)
plt.plot(history["train_loss"], label="Train")
plt.plot(history["val_loss"], label="Validation")
plt.title("Loss"); plt.legend(); plt.grid()
plt.savefig(OUTPUT_DIR / "curves_final.png", dpi=500, bbox_inches='tight')

print(f"All results saved → {OUTPUT_DIR}")
